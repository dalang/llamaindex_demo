"""Query service for RAG system."""

import logging

import chromadb
from llama_index.core import Settings, VectorStoreIndex
from llama_index.core.postprocessor import SimilarityPostprocessor
from llama_index.embeddings.zhipuai import ZhipuAIEmbedding
from llama_index.llms.zhipuai import ZhipuAI
from llama_index.vector_stores.chroma import ChromaVectorStore

import config
from reranker import TEIReranker

logger = logging.getLogger(__name__)


class QueryService:
    """Handles querying the RAG system."""

    def __init__(self):
        """Initialize query service."""
        # éªŒè¯ API key
        if not config.ZHIPUAI_API_KEY:
            raise ValueError("âŒ ZHIPUAI_API_KEY æœªè®¾ç½®ï¼è¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½® API key")

        # é…ç½®æ¨¡å‹
        self.llm = ZhipuAI(
            model=config.LLM_MODEL,
            api_key=config.ZHIPUAI_API_KEY,
        )

        self.embed_model = ZhipuAIEmbedding(
            model=config.EMBEDDING_MODEL,
            api_key=config.ZHIPUAI_API_KEY,
        )

        Settings.llm = self.llm
        Settings.embed_model = self.embed_model

        # è¿æ¥åˆ°ç°æœ‰çš„ Chroma æ•°æ®åº“
        self.chroma_client = chromadb.PersistentClient(path=config.CHROMA_PERSIST_DIR)

        try:
            self.chroma_collection = self.chroma_client.get_collection(
                name=config.COLLECTION_NAME
            )
        except Exception as e:
            raise RuntimeError(
                f"âŒ æœªæ‰¾åˆ°ç´¢å¼•ï¼è¯·å…ˆè¿è¡Œ 'python indexer.py' æ„å»ºç´¢å¼•ã€‚\né”™è¯¯: {e}"
            )

        # ä»ç°æœ‰å­˜å‚¨åŠ è½½ç´¢å¼•
        vector_store = ChromaVectorStore(chroma_collection=self.chroma_collection)
        self.index = VectorStoreIndex.from_vector_store(
            vector_store=vector_store,
            embed_model=self.embed_model,
        )

        # é…ç½® node postprocessorsï¼ˆåŒ…æ‹¬ rerankï¼‰
        node_postprocessors = self._setup_postprocessors()

        # åˆ›å»ºæŸ¥è¯¢å¼•æ“
        self.query_engine = self.index.as_query_engine(
            similarity_top_k=config.SIMILARITY_TOP_K,
            response_mode="compact",
            node_postprocessors=node_postprocessors,
        )

        logger.info("âœ… æŸ¥è¯¢æœåŠ¡åˆå§‹åŒ–å®Œæˆ")

    def _setup_postprocessors(self) -> list:
        """Setup node postprocessors including reranker.

        Returns:
            List of postprocessors to apply to retrieved nodes.
        """
        postprocessors = []

        if config.USE_RERANK:
            try:
                reranker = TEIReranker(
                    api_url=config.RERANK_API_URL,
                    top_n=config.RERANK_TOP_N,
                    timeout=config.RERANK_TIMEOUT,
                )
                postprocessors.append(reranker)
                logger.info(
                    f"âœ… TEI Rerank å¯ç”¨: {config.RERANK_API_URL}, "
                    f"åˆå§‹æ£€ç´¢={config.SIMILARITY_TOP_K}, "
                    f"rerankå={config.RERANK_TOP_N}"
                )
            except Exception as e:
                logger.warning(f"âš ï¸  Rerank åˆå§‹åŒ–å¤±è´¥: {e}")

        return postprocessors

    def query(self, question: str, return_sources: bool = True):
        """Query the RAG system.

        Args:
            question: The question to query.
            return_sources: Whether to return source nodes.

        Returns:
            Dictionary containing question, answer, and optional sources.
        """
        logger.info(f"ğŸ” æŸ¥è¯¢: {question}")

        response = self.query_engine.query(question)

        result = {
            "question": question,
            "answer": str(response),
            "sources": [],
        }

        if return_sources and hasattr(response, "source_nodes"):
            for i, node in enumerate(response.source_nodes, 1):
                source = {
                    "chunk_id": i,
                    "score": node.score,
                    "text": node.text[:100] + "..."
                    if len(node.text) > 100
                    else node.text,
                    "metadata": node.node.metadata,
                }
                result["sources"].append(source)

        return result


def main():
    """Interactive query mode."""
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    )

    service = QueryService()

    print("\n" + "=" * 70)
    print("ğŸ’¬ RAG æŸ¥è¯¢æœåŠ¡ (è¾“å…¥ 'quit' é€€å‡º)")
    print("=" * 70)

    while True:
        question = input("\nâ“ è¯·è¾“å…¥é—®é¢˜: ").strip()
        if question.lower() in ["quit", "exit", "q"]:
            break

        if not question:
            continue

        result = service.query(question)

        print("\n" + "=" * 70)
        print("ğŸ’¡ å›ç­”:")
        print("-" * 70)
        print(result["answer"])

        if result["sources"]:
            print("\n" + "=" * 70)
            print("ğŸ“š ç›¸å…³æ¥æº:")
            for src in result["sources"]:
                print(f"\nğŸ“„ æ¥æº {src['chunk_id']} (ç›¸ä¼¼åº¦: {src['score']:.4f})")
                print(f"   {src['text']}")
                print(f"   ğŸ“Œ {src['metadata']}")
        print("=" * 70)


if __name__ == "__main__":
    main()
